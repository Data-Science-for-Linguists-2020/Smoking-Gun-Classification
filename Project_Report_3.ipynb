{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report III: Finalizing Data Cleaning, Machine Learning\n",
    "___\n",
    "**Brief:**<br>\n",
    "In this report, I'll expand to the data cleaning process to all of the users in the Enron directory, explore the text and tag data, and finally use a bag-of-words approach to make a simple classifier.\n",
    "\n",
    "**Sections:**<br>\n",
    "1. [Searching All Files](#1)\n",
    "    - [Trying OS](#1a)\n",
    "    - [Adapting Old Functions](#1b)\n",
    "    - [A Complete DataFrame](#1c)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching All Files\n",
    "<a id='1a'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Trying OS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and setting root\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader as cr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import email.parser\n",
    "corpus_root = '../../../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring os.walk\n",
    "path = corpus_root + \"Enron_Emails/maildir/\"\n",
    "#for file in os.walk(path):\n",
    "    #file[0] #filepath of each file\n",
    "    #file[1] #directory (names) in each file\n",
    "    #file[2] #files of every directory, rock bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: I could see how this module would be really useful, but honestly it looks like more of a summer project than something I can effectively use this term.\n",
    "<a id='1b'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Adapting Old Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allen-p's folders: \n",
      "arnold-j's folders: \n",
      "arora-h's folders: \n",
      "badeer-r's folders: \n",
      "bailey-s's folders: \n",
      "bass-e's folders: \n",
      "baughman-d's folders: \n",
      "beck-s's folders: \n",
      "benson-r's folders: \n",
      "blair-l's folders: \n",
      "brawner-s's folders: \n",
      "buy-r's folders: \n",
      "campbell-l's folders: \n",
      "carson-m's folders: \n",
      "causholli-m's folders: \n",
      "corman-s's folders: \n",
      "crandell-s's folders: \n",
      "cuilla-m's folders: \n",
      "dasovich-j's folders: \n",
      "davis-d's folders: \n",
      "dean-c's folders: \n",
      "delainey-d's folders: \n",
      "derrick-j's folders: \n",
      "dickson-s's folders: \n",
      "donoho-l's folders: \n",
      "donohoe-t's folders: \n",
      "dorland-c's folders: \n",
      "ermis-f's folders: \n",
      "farmer-d's folders: \n",
      "fischer-m's folders: \n",
      "forney-j's folders: \n",
      "fossum-d's folders: \n",
      "gang-l's folders: \n",
      "gay-r's folders: \n",
      "geaccone-t's folders: \n",
      "germany-c's folders: \n",
      "gilbertsmith-d's folders: \n",
      "giron-d's folders: \n",
      "griffith-j's folders: \n",
      "grigsby-m's folders: \n",
      "guzman-m's folders: \n",
      "haedicke-m's folders: \n",
      "hain-m's folders: \n",
      "harris-s's folders: \n",
      "hayslett-r's folders: \n",
      "heard-m's folders: \n",
      "hendrickson-s's folders: \n",
      "hernandez-j's folders: \n",
      "hodge-j's folders: \n",
      "holst-k's folders: \n",
      "horton-s's folders: \n",
      "hyatt-k's folders: \n",
      "hyvl-d's folders: \n",
      "jones-t's folders: \n",
      "kaminski-v's folders: \n",
      "kean-s's folders: \n",
      "keavey-p's folders: \n",
      "keiser-k's folders: \n",
      "king-j's folders: \n",
      "kitchen-l's folders: \n",
      "kuykendall-t's folders: \n",
      "lavorato-j's folders: \n",
      "lay-k's folders: \n",
      "lenhart-m's folders: \n",
      "lewis-a's folders: \n",
      "linder-e's folders: \n",
      "lokay-m's folders: \n",
      "lokey-t's folders: \n",
      "love-p's folders: \n",
      "lucci-p's folders: \n",
      "maggi-m's folders: \n",
      "mann-k's folders: \n",
      "martin-t's folders: \n",
      "may-l's folders: \n",
      "mccarty-d's folders: \n",
      "mcconnell-m's folders: \n",
      "mckay-b's folders: \n",
      "mckay-j's folders: \n",
      "mclaughlin-e's folders: \n",
      "merriss-s's folders: \n",
      "meyers-a's folders: \n",
      "mims-thurston-p's folders: \n",
      "motley-m's folders: \n",
      "neal-s's folders: \n",
      "nemec-g's folders: \n",
      "panus-s's folders: \n",
      "parks-j's folders: \n",
      "pereira-s's folders: \n",
      "perlingiere-d's folders: \n",
      "phanis-s's folders: \n",
      "pimenov-v's folders: \n",
      "platter-p's folders: \n",
      "presto-k's folders: \n",
      "quenet-j's folders: \n",
      "quigley-d's folders: \n",
      "rapp-b's folders: \n",
      "reitmeyer-j's folders: \n",
      "richey-c's folders: \n",
      "ring-a's folders: \n",
      "ring-r's folders: \n",
      "rodrique-r's folders: \n",
      "rogers-b's folders: \n",
      "ruscitti-k's folders: \n",
      "sager-e's folders: \n",
      "saibi-e's folders: \n",
      "salisbury-h's folders: \n",
      "sanchez-m's folders: \n",
      "sanders-r's folders: \n",
      "scholtes-d's folders: \n",
      "schoolcraft-d's folders: \n",
      "schwieger-j's folders: \n",
      "scott-s's folders: \n",
      "semperger-c's folders: \n",
      "shackleton-s's folders: \n",
      "shankman-j's folders: \n",
      "shapiro-r's folders: \n",
      "shively-h's folders: \n",
      "skilling-j's folders: \n",
      "slinger-r's folders: \n",
      "smith-m's folders: \n",
      "solberg-g's folders: \n",
      "south-s's folders: \n",
      "staab-t's folders: \n",
      "stclair-c's folders: \n",
      "steffes-j's folders: \n",
      "stepenovitch-j's folders: \n",
      "stokley-c's folders: \n",
      "storey-g's folders: \n",
      "sturm-f's folders: \n",
      "swerzbin-m's folders: \n",
      "symes-k's folders: \n",
      "taylor-m's folders: \n",
      "tholt-j's folders: \n",
      "thomas-p's folders: \n",
      "townsend-j's folders: \n",
      "tycholiz-b's folders: \n",
      "ward-k's folders: \n",
      "watson-k's folders: \n",
      "weldon-c's folders: \n",
      "whalley-g's folders: \n",
      "whalley-l's folders: \n",
      "white-s's folders: \n",
      "whitt-m's folders: \n",
      "williams-j's folders: \n",
      "williams-w3's folders: \n",
      "wolfe-j's folders: \n",
      "ybarbo-p's folders: \n",
      "zipper-a's folders: \n",
      "zufferli-j's folders: \n"
     ]
    }
   ],
   "source": [
    "for name in os.listdir(path):\n",
    "    relpath = path + name + \"/\"\n",
    "    print(name + \"'s folders: \")\n",
    "    #for folder in os.listdir(relpath):\n",
    "        #filepath = relpath + folder + \"/\"\n",
    "        #print(\"folder<\" + folder + \">: \")\n",
    "        #for file in os.listdir(filepath):\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: This is the old \"readEmailHead\" method, but now we can simplify the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readEmailHead(file):\n",
    "    with open(file) as fd:\n",
    "        pp = email.parser.Parser()\n",
    "        header = pp.parse(fd, headersonly=True) #where the magic happens. works on all MIME email formats.\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = []\n",
    "for name in os.listdir(path):\n",
    "    relpath = path + name + \"/\"\n",
    "    print(name + \" loaded\")\n",
    "    for folder in os.listdir(relpath):\n",
    "        filepath = relpath + folder + \"/\"\n",
    "        try:\n",
    "            for file in os.listdir(filepath):\n",
    "                try:\n",
    "                    emails.append(readEmailHead(filepath+file))\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first thing we do... save them emails.\n",
    "file = open('emails', 'wb')\n",
    "pickle.dump(emails, file, -1)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for email in emails:\n",
    "    texts.append(getText(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)\n",
    "len(emails)\n",
    "emails[:10]\n",
    "emails[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1c'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A Full DataFrame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('df_keys', 'rb')\n",
    "df_keys = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHeaderDF(emails):\n",
    "    values = []\n",
    "    for email in emails:\n",
    "        values.append(email.values())\n",
    "    email_df = pd.DataFrame(values, columns=df_keys)\n",
    "    return email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df = makeHeaderDF(emails)\n",
    "emails_df[\"text\"] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching All Files: Summary\n",
    "In the past three sections, we were finally able to load the vast majority of the Enron Corpus into Python objects. So how'd we do it, and why'd it take so long? This summary will act as a summary on the Data Organization process as a whole.\n",
    "1. **New Techniques: OS**\n",
    "    - The OS library is famed for its ability to parse through files concisely, so I tried to use its *.walk(path)* command. This command will perform a traversal across the entire directory, as well as any subdirectories within. Sounds perfect for my project! Unfortunately, the command returned a lot more than I really needed. Feel free to uncomment my outputs, see for yourself! Just couldn't see myself getting anything productive out of the mess of a list.<br><br>\n",
    "2. **The Final Reader**\n",
    "    - My final reader actually uses the OS library as well, but it really only uses one command: *.listdir()*. This command is quite simple: it just returns the contents of a directory. This is *much* simpler than *os.walk()*, so I just iterated across every directory, opening every item in each of the top two directories (users, folders) and then parsing every item in the bottom directories (should be all files). Since this is likely to be the way I traverse this data from now on, here's a few things to know: \n",
    "        - For the most part, this has excellent coverage. When I run this again, I'm going to be sure to include a counter of errors so I can actually report out on this, but it was mostly very efficient--only two things trip it up. The first exception comes from stray files that are in the user level folders, for instance *allen-p*. Sometimes there's just a stray file name *1* hanging around in there. The second exception is thrown for a more legitimate reason: the bottom isn't always the bottom. Every once in a while, there is a user that has folders within their folders. My search feeds those folders into a method that takes files. Error. That being said, these errors combined only crashed my search after it loaded 10 or so users, and any given error probably only skips 1-10 files.\n",
    "        - This search is predicated on a specific shape of the file hierarchy. Like I mentioned above, this search is two folders deep, then it reads through all of the files. This won't work on other structures, probably why os.walk() exists.\n",
    "    - As a final thought about this search, I would really like to use the CRC for it. The search has been going on for a few hours now and is severly hampering my progress. As of now, I'm going to have to abandon using the whole corpus and go with a reduced version. The one problem with using research computing is getting the Enron Corpus onto the CRC, which isn't really a drag and drop situation.<br><br>\n",
    "3. **Why'd It Take So Long?\n",
    "   This question is mostly for me, as the time really feels like it got away from me on this one, but if I write convincingly enough maybe it'll help my grade too.\n",
    "    - **I spent a lot of time getting familiar with two libraries: email.parser and OS.** Before I learned about these (*ESPECIALLY EMAIL.PARSER*), I spend lots of time doing the code equivalent of kicking and screaming.\n",
    "    - **I didn't spend enough time planning ahead.** This is probably the biggest mistake that cost me time. A lot of times I really failed to consider what I would be doing in the future and how that affected what functions/libraries I made/utilized. A perfect example of this is the recent *readEmailHead* function, or more poignantly, the *makeEmailDF* function. I wrote them twice for little to no reason.\n",
    "    - **I didn't pay close enough attention to my data.** This goes hand in hand with the above comment, and applies mostly early on. If I did this all over again, I would have definitely sketched out an entire plan of attack in detail--what libraries I'm going to use, how I get from one object to another, inconsistencies in directory depth, etc.<br><br>\n",
    "4. **In Conclusion<br>\n",
    "    Ultimately, I'm grateful that I'm still working on my data organization the night before our third progress report is due. While this was not the most unorganized of data, it did also resist simple conversions like *pd.read_x*. It required me to make use of data pipelining skills and to write my first productive functions in Python.\n",
    "    Also, I do feel that I have a great background in NLP statistical techniques/ML because of the extent to which we explored them in the homeworks, whereas handling data in the wild is hard to teach. I'm 100% planning on continuing to expand my work on this project over the summer, hopefully expanding to complex ML techniques and eventually Network Theory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
